// Generated by `wit-bindgen` 0.19.2. DO NOT EDIT!
#ifndef __BINDINGS_ML_H
#define __BINDINGS_ML_H
#ifdef __cplusplus
extern "C" {
#endif

#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <stdbool.h>

typedef struct {
  uint8_t*ptr;
  size_t len;
} ml_string_t;

// The dimensions of a tensor.
// 
// The array length matches the tensor rank and each element in the array describes the size of
// each dimension
typedef struct {
  uint32_t *ptr;
  size_t len;
} wasi_nn_tensor_tensor_dimensions_t;

// The type of the elements in a tensor.
typedef uint8_t wasi_nn_tensor_tensor_type_t;

#define WASI_NN_TENSOR_TENSOR_TYPE_FP16 0
#define WASI_NN_TENSOR_TENSOR_TYPE_FP32 1
#define WASI_NN_TENSOR_TENSOR_TYPE_FP64 2
#define WASI_NN_TENSOR_TENSOR_TYPE_BF16 3
#define WASI_NN_TENSOR_TENSOR_TYPE_U8 4
#define WASI_NN_TENSOR_TENSOR_TYPE_I32 5
#define WASI_NN_TENSOR_TENSOR_TYPE_I64 6

// The tensor data.
// 
// Initially conceived as a sparse representation, each empty cell would be filled with zeros
// and the array length must match the product of all of the dimensions and the number of bytes
// in the type (e.g., a 2x2 tensor with 4-byte f32 elements would have a data array of length
// 16). Naturally, this representation requires some knowledge of how to lay out data in
// memory--e.g., using row-major ordering--and could perhaps be improved.
typedef struct {
  uint8_t *ptr;
  size_t len;
} wasi_nn_tensor_tensor_data_t;

typedef struct wasi_nn_tensor_own_tensor_t {
  int32_t __handle;
} wasi_nn_tensor_own_tensor_t;

typedef struct wasi_nn_tensor_borrow_tensor_t {
  int32_t __handle;
} wasi_nn_tensor_borrow_tensor_t;

typedef uint8_t wasi_nn_errors_error_code_t;

// Caller module passed an invalid argument.
#define WASI_NN_ERRORS_ERROR_CODE_INVALID_ARGUMENT 0
// Invalid encoding.
#define WASI_NN_ERRORS_ERROR_CODE_INVALID_ENCODING 1
// The operation timed out.
#define WASI_NN_ERRORS_ERROR_CODE_TIMEOUT 2
// Runtime Error.
#define WASI_NN_ERRORS_ERROR_CODE_RUNTIME_ERROR 3
// Unsupported operation.
#define WASI_NN_ERRORS_ERROR_CODE_UNSUPPORTED_OPERATION 4
// Graph is too large.
#define WASI_NN_ERRORS_ERROR_CODE_TOO_LARGE 5
// Graph not found.
#define WASI_NN_ERRORS_ERROR_CODE_NOT_FOUND 6
// The operation is insecure or has insufficient privilege to be performed.
// e.g., cannot access a hardware feature requested
#define WASI_NN_ERRORS_ERROR_CODE_SECURITY 7
// The operation failed for an unspecified reason.
#define WASI_NN_ERRORS_ERROR_CODE_UNKNOWN 8

typedef struct wasi_nn_errors_own_error_t {
  int32_t __handle;
} wasi_nn_errors_own_error_t;

typedef struct wasi_nn_errors_borrow_error_t {
  int32_t __handle;
} wasi_nn_errors_borrow_error_t;

typedef wasi_nn_tensor_tensor_data_t wasi_nn_inference_tensor_data_t;

typedef struct wasi_nn_inference_own_graph_execution_context_t {
  int32_t __handle;
} wasi_nn_inference_own_graph_execution_context_t;

typedef struct wasi_nn_inference_borrow_graph_execution_context_t {
  int32_t __handle;
} wasi_nn_inference_borrow_graph_execution_context_t;

typedef wasi_nn_tensor_own_tensor_t wasi_nn_inference_own_tensor_t;

typedef wasi_nn_errors_own_error_t wasi_nn_inference_own_error_t;

typedef struct {
  bool is_err;
  union {
    wasi_nn_inference_own_error_t err;
  } val;
} wasi_nn_inference_result_void_own_error_t;

typedef struct {
  bool is_err;
  union {
    wasi_nn_inference_own_tensor_t ok;
    wasi_nn_inference_own_error_t err;
  } val;
} wasi_nn_inference_result_own_tensor_own_error_t;

typedef struct wasi_nn_graph_own_graph_t {
  int32_t __handle;
} wasi_nn_graph_own_graph_t;

typedef struct wasi_nn_graph_borrow_graph_t {
  int32_t __handle;
} wasi_nn_graph_borrow_graph_t;

// Describes the encoding of the graph. This allows the API to be implemented by various
// backends that encode (i.e., serialize) their graph IR with different formats.
typedef uint8_t wasi_nn_graph_graph_encoding_t;

#define WASI_NN_GRAPH_GRAPH_ENCODING_OPENVINO 0
#define WASI_NN_GRAPH_GRAPH_ENCODING_ONNX 1
#define WASI_NN_GRAPH_GRAPH_ENCODING_TENSORFLOW 2
#define WASI_NN_GRAPH_GRAPH_ENCODING_PYTORCH 3
#define WASI_NN_GRAPH_GRAPH_ENCODING_TENSORFLOWLITE 4
#define WASI_NN_GRAPH_GRAPH_ENCODING_AUTODETECT 5
#define WASI_NN_GRAPH_GRAPH_ENCODING_GGML 6

// Define where the graph should be executed.
typedef uint8_t wasi_nn_graph_execution_target_t;

#define WASI_NN_GRAPH_EXECUTION_TARGET_CPU 0
#define WASI_NN_GRAPH_EXECUTION_TARGET_GPU 1
#define WASI_NN_GRAPH_EXECUTION_TARGET_TPU 2

// The graph initialization data.
// 
// This gets bundled up into an array of buffers because implementing backends may encode their
// graph IR in parts (e.g., OpenVINO stores its IR and weights separately).
typedef struct {
  uint8_t *ptr;
  size_t len;
} wasi_nn_graph_graph_builder_t;

typedef wasi_nn_inference_own_graph_execution_context_t wasi_nn_graph_own_graph_execution_context_t;

typedef wasi_nn_errors_own_error_t wasi_nn_graph_own_error_t;

typedef struct {
  bool is_err;
  union {
    wasi_nn_graph_own_graph_execution_context_t ok;
    wasi_nn_graph_own_error_t err;
  } val;
} wasi_nn_graph_result_own_graph_execution_context_own_error_t;

typedef struct {
  wasi_nn_graph_graph_builder_t *ptr;
  size_t len;
} ml_list_graph_builder_t;

typedef struct {
  bool is_err;
  union {
    wasi_nn_graph_own_graph_t ok;
    wasi_nn_graph_own_error_t err;
  } val;
} wasi_nn_graph_result_own_graph_own_error_t;

// Imported Functions from `wasi:nn/tensor`
extern wasi_nn_tensor_own_tensor_t wasi_nn_tensor_constructor_tensor(wasi_nn_tensor_tensor_dimensions_t *dimensions, wasi_nn_tensor_tensor_type_t ty, wasi_nn_tensor_tensor_data_t *data);
// Describe the size of the tensor (e.g., 2x2x2x2 -> [2, 2, 2, 2]). To represent a tensor
// containing a single value, use `[1]` for the tensor dimensions.
extern void wasi_nn_tensor_method_tensor_dimensions(wasi_nn_tensor_borrow_tensor_t self, wasi_nn_tensor_tensor_dimensions_t *ret);
// Describe the type of element in the tensor (e.g., `f32`).
extern wasi_nn_tensor_tensor_type_t wasi_nn_tensor_method_tensor_ty(wasi_nn_tensor_borrow_tensor_t self);
// Return the tensor data.
extern void wasi_nn_tensor_method_tensor_data(wasi_nn_tensor_borrow_tensor_t self, wasi_nn_tensor_tensor_data_t *ret);

// Imported Functions from `wasi:nn/errors`
extern wasi_nn_errors_own_error_t wasi_nn_errors_constructor_error(wasi_nn_errors_error_code_t code, ml_string_t *data);
// Return the error code.
extern wasi_nn_errors_error_code_t wasi_nn_errors_method_error_code(wasi_nn_errors_borrow_error_t self);
// Errors can propagated with backend specific status through a string value.
extern void wasi_nn_errors_method_error_data(wasi_nn_errors_borrow_error_t self, ml_string_t *ret);

// Imported Functions from `wasi:nn/inference`
// Define the inputs to use for inference.
extern void wasi_nn_inference_method_graph_execution_context_set_input(wasi_nn_inference_borrow_graph_execution_context_t self, ml_string_t *name, wasi_nn_inference_own_tensor_t tensor, wasi_nn_inference_result_void_own_error_t *ret);
// Compute the inference on the given inputs.
// 
// Note the expected sequence of calls: `set-input`, `compute`, `get-output`. TODO: this
// expectation could be removed as a part of
// https://github.com/WebAssembly/wasi-nn/issues/43.
extern void wasi_nn_inference_method_graph_execution_context_compute(wasi_nn_inference_borrow_graph_execution_context_t self, wasi_nn_inference_result_void_own_error_t *ret);
// Extract the outputs after inference.
extern void wasi_nn_inference_method_graph_execution_context_get_output(wasi_nn_inference_borrow_graph_execution_context_t self, ml_string_t *name, wasi_nn_inference_result_own_tensor_own_error_t *ret);

// Imported Functions from `wasi:nn/graph`
extern void wasi_nn_graph_method_graph_init_execution_context(wasi_nn_graph_borrow_graph_t self, wasi_nn_graph_result_own_graph_execution_context_own_error_t *ret);
// Load a `graph` from an opaque sequence of bytes to use for inference.
extern void wasi_nn_graph_load(ml_list_graph_builder_t *builder, wasi_nn_graph_graph_encoding_t encoding, wasi_nn_graph_execution_target_t target, wasi_nn_graph_result_own_graph_own_error_t *ret);
// Load a `graph` by name.
// 
// How the host expects the names to be passed and how it stores the graphs for retrieval via
// this function is **implementation-specific**. This allows hosts to choose name schemes that
// range from simple to complex (e.g., URLs?) and caching mechanisms of various kinds.
extern void wasi_nn_graph_load_by_name(ml_string_t *name, wasi_nn_graph_result_own_graph_own_error_t *ret);

// Helper Functions

void wasi_nn_tensor_tensor_dimensions_free(wasi_nn_tensor_tensor_dimensions_t *ptr);

void wasi_nn_tensor_tensor_data_free(wasi_nn_tensor_tensor_data_t *ptr);

extern void wasi_nn_tensor_tensor_drop_own(wasi_nn_tensor_own_tensor_t handle);

extern wasi_nn_tensor_borrow_tensor_t wasi_nn_tensor_borrow_tensor(wasi_nn_tensor_own_tensor_t handle);

extern void wasi_nn_errors_error_drop_own(wasi_nn_errors_own_error_t handle);

extern wasi_nn_errors_borrow_error_t wasi_nn_errors_borrow_error(wasi_nn_errors_own_error_t handle);

void wasi_nn_inference_tensor_data_free(wasi_nn_inference_tensor_data_t *ptr);

extern void wasi_nn_inference_graph_execution_context_drop_own(wasi_nn_inference_own_graph_execution_context_t handle);

extern wasi_nn_inference_borrow_graph_execution_context_t wasi_nn_inference_borrow_graph_execution_context(wasi_nn_inference_own_graph_execution_context_t handle);

void wasi_nn_inference_result_void_own_error_free(wasi_nn_inference_result_void_own_error_t *ptr);

void wasi_nn_inference_result_own_tensor_own_error_free(wasi_nn_inference_result_own_tensor_own_error_t *ptr);

extern void wasi_nn_graph_graph_drop_own(wasi_nn_graph_own_graph_t handle);

extern wasi_nn_graph_borrow_graph_t wasi_nn_graph_borrow_graph(wasi_nn_graph_own_graph_t handle);

void wasi_nn_graph_graph_builder_free(wasi_nn_graph_graph_builder_t *ptr);

void wasi_nn_graph_result_own_graph_execution_context_own_error_free(wasi_nn_graph_result_own_graph_execution_context_own_error_t *ptr);

void ml_list_graph_builder_free(ml_list_graph_builder_t *ptr);

void wasi_nn_graph_result_own_graph_own_error_free(wasi_nn_graph_result_own_graph_own_error_t *ptr);

// Transfers ownership of `s` into the string `ret`
void ml_string_set(ml_string_t *ret, char*s);

// Creates a copy of the input nul-terminate string `s` and
// stores it into the component model string `ret`.
void ml_string_dup(ml_string_t *ret, const char*s);

// Deallocates the string pointed to by `ret`, deallocating
// the memory behind the string.
void ml_string_free(ml_string_t *ret);

#ifdef __cplusplus
}
#endif
#endif
